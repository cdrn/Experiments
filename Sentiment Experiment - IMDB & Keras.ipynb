{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "This notebook documents some of my (imitative) experiences trying to implement and understand neural network approaches to sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First i'm going to try implement a CNN using Keras and Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.datasets import imdb\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#keras utilities\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# import and register tensorflow session #\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "# import keras and register with tensorflow session #\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "\n",
    "# concat together test and train sets for full set of data/labels #\n",
    "X = numpy.concatenate((X_train, X_test), axis=0)\n",
    "y = numpy.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "# summarize size\n",
    "print(\"Training data: \")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 2, 9, 6, 1225, 446, 2, 45, 2174, 84, 2, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 2, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 2, 5, 4241, 18, 4, 2, 2, 250, 11, 1818, 2, 4, 4217, 2, 747, 1115, 372, 1890, 1006, 541, 2, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "         list([1, 1446, 2, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 2, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 2, 2, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 2, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])], dtype=object),\n",
       "  array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([ list([1, 89, 27, 2, 2, 17, 199, 132, 5, 4191, 16, 1339, 24, 8, 760, 4, 1385, 7, 4, 22, 1368, 2, 16, 2, 17, 1635, 7, 2, 1368, 9, 4, 1357, 8, 14, 991, 13, 877, 38, 19, 27, 239, 13, 100, 235, 61, 483, 2, 4, 7, 4, 20, 131, 1102, 72, 8, 14, 251, 27, 1146, 7, 308, 16, 735, 1517, 17, 29, 144, 28, 77, 2305, 18, 12]),\n",
       "         list([1, 3452, 7, 2, 517, 522, 31, 314, 17, 1909, 2046, 2, 2, 2, 83, 4, 2314, 673, 33, 27, 568, 1709, 2923, 32, 4, 189, 22, 11, 975, 4135, 29, 2376, 4, 1287, 7, 4, 2, 4217, 15, 1435, 455, 1394, 848, 1538, 4031, 96, 145, 11, 4, 204, 2, 297, 2, 29, 3044, 4, 1287, 8, 35, 4383, 1609, 121, 2, 1233, 980, 2, 2100, 2, 2, 2, 3681, 304, 4, 1287, 145, 8, 41, 1472, 50, 2, 2, 2, 2, 4364, 34, 2782, 2, 145, 295, 174, 772, 6, 2, 18, 274, 961, 90, 145, 8, 4041, 113, 155, 92, 140, 17, 2, 69, 3205, 2, 505, 46, 24, 8, 30, 4, 132, 7, 41, 1306, 103, 32, 38, 59, 2, 90, 11, 6, 297, 2, 33, 63, 2, 9, 329, 74, 654, 137, 2, 304, 6, 4548, 2, 2949, 2, 41, 772, 15, 274, 961, 41, 145, 8, 113, 11, 4, 2995, 7, 6, 668, 4217, 1810, 17, 6, 3452, 1082, 181, 8, 30, 1571, 11, 3161, 2350, 28, 8, 157, 295, 8, 79, 8, 6, 2, 11, 162, 2, 121, 2, 1249, 648, 69, 77, 3554, 19, 4, 2, 887, 8, 4416, 68, 4123, 145, 83, 406, 2350, 4, 2350, 7, 2, 2, 3509, 1851, 27, 980, 2, 2, 2, 37, 26, 199, 23, 4, 521, 39, 3408, 1697, 2297, 7, 568, 3864, 2, 308, 3659, 80, 81, 1780, 10, 10, 526, 34, 2, 2, 13, 119, 3452, 7, 2, 4, 229, 34, 1561, 2, 9, 87, 253, 55, 702, 728, 545, 441, 2072, 958, 7, 85, 189, 22, 19, 52, 2, 39, 4, 636, 720, 121, 75, 67, 1655, 2, 2, 2377, 39, 4, 2553, 4, 4971, 108, 2281, 2, 2, 4626, 2, 39, 4, 6, 1726, 23, 4903, 890, 201, 488, 4664, 2377, 39, 4, 2195, 3135, 8, 4, 2974, 343, 39, 3452, 7, 2, 2, 54, 12, 2360, 2, 4, 172, 136, 3452, 7, 2, 115, 304, 410, 615, 63, 9, 43, 17, 73, 50, 26, 775, 7, 31, 2433, 532, 2, 1994, 15, 2039, 4142, 93, 2, 6, 171, 153, 908, 12, 152, 306, 1595, 8, 2, 253, 33, 410, 4, 189, 512, 11, 831, 13, 119, 4, 136, 54, 3509, 2, 26, 260, 6, 2711, 2, 731, 2599, 15, 2, 2, 29, 166, 163, 2, 795, 2, 469, 198, 24, 8, 135, 15, 50, 218, 6, 1543, 52, 22, 11, 50, 17, 73, 88, 50, 91, 434, 9, 167, 2, 1030, 8, 987, 52, 841, 6, 147, 281, 7, 253, 199, 406, 3161, 732, 7, 105, 26, 1451, 4091, 17, 257, 2162, 2712, 68, 205, 732, 7, 4816, 712, 15, 4, 4951, 7, 2, 15, 36, 26, 1200, 496, 62, 540, 1203, 2536, 3452, 7, 2, 9, 87, 18, 4, 91, 173, 47, 15, 194, 352, 2, 44, 12, 33, 44, 2476, 1782, 1782, 13, 144, 440, 38, 4, 64, 155, 15, 13, 80, 135, 9, 15, 49, 7, 4, 2, 302, 34, 1842, 26, 6, 117, 3463, 2631, 13, 191, 377, 101, 1683, 139, 11, 3452, 7, 2, 345, 2670, 4, 22, 152, 2, 4, 541, 599, 19, 6, 646, 2, 3681, 2, 2, 83, 4472, 393, 11, 3532, 6, 2, 2, 3490, 84, 2, 23, 2, 7, 3062, 294, 112, 2, 34, 6, 666, 2832, 6, 3314, 125, 2, 2, 998, 2, 2, 4, 116, 9, 184, 52, 2, 17, 2, 9, 55, 163, 17, 29, 2, 4, 31, 2433, 46, 13, 82, 40, 4, 139, 19, 2, 33, 4, 454, 169, 41, 55, 1279, 54, 442, 1658, 32, 15, 2, 2, 13, 191, 30, 4, 64, 31, 1348, 13, 1276, 104, 3452, 7, 2, 9, 6, 777, 22, 964, 722, 39, 380, 8, 1363, 87, 1285, 189, 11, 3215, 4160, 33, 64, 2, 234, 196, 12, 115, 461, 357, 42, 753, 6, 965, 1640, 7, 1923, 106, 12, 17, 515, 17, 25, 70]),\n",
       "         list([1, 1868, 256, 34, 31, 7, 4, 91, 2305, 1507, 7, 4, 236, 2068, 7, 14, 1117, 5, 82, 31, 7, 4, 91, 1020, 1507, 2, 4686, 46, 7, 2415, 59, 9, 389, 9, 175, 173, 15, 59, 299, 4, 2, 2, 9, 4, 3114, 5, 1805, 7, 4, 298, 438, 10, 10, 2, 3365, 9, 2, 5, 41, 658, 742, 217, 73, 1391, 34, 530, 284, 5, 82, 735, 2286, 1024, 1487, 3740, 2828, 7, 4, 2, 255, 47, 6, 254, 58, 19, 4, 2, 3365, 7, 27, 31, 283, 155, 5, 4846, 27, 2, 339, 4, 338, 577, 3996, 2, 2, 1516, 2, 47, 96, 99, 76, 873, 7, 41, 57, 2010, 4, 65, 304, 6, 55, 821, 650, 23, 4, 4696, 7, 6, 4069, 11, 14, 20, 4, 64, 577, 47, 8, 276, 41, 113, 23, 1070, 8, 459, 18, 4, 738, 7, 409, 50, 9, 210, 31, 11, 175, 223, 37, 1590, 15, 243, 7, 4756, 3996, 9, 1612, 4, 454, 7, 4, 20, 21, 17, 58, 4097, 59, 630, 56, 1897, 41, 2, 113, 58, 2, 8, 41, 223, 59, 60, 1643, 41, 1633, 89, 81, 25, 81, 27, 175, 251, 11, 5, 46, 5, 1337, 2, 12, 15, 9, 51, 372, 81, 6, 176, 7, 51, 13, 683, 2504, 157, 2, 75, 2170, 75, 4290, 75, 2, 75, 3218, 75, 2, 75, 26, 4, 118, 369, 75, 26, 4, 4727, 2728, 49, 7, 178, 40, 199, 372, 11, 14, 20, 28, 4, 404, 4421, 26, 4, 1987, 2, 18, 4, 436, 223, 5, 82, 81, 32, 15, 2504, 157, 15, 9, 1868, 3996, 5, 111, 372, 11, 263, 926, 111, 7, 178, 28, 460, 825, 143, 15, 868, 7, 113, 54, 263, 846, 559, 5, 1131, 13, 28, 77, 50, 36, 43, 435, 99, 185, 13, 28, 348, 61, 846, 61, 1216, 21, 13, 115, 2717, 98, 17, 73, 17, 54, 13, 69, 8, 297, 68, 555, 5, 69, 8, 1135, 11, 68, 3730, 14, 20, 2, 4, 635, 7, 113, 382, 12, 9, 619, 21, 15, 9, 89, 113, 9, 33, 211, 742, 6, 2489, 33, 2, 9, 2732, 415, 37, 739, 8, 104, 15, 27, 157, 9, 53, 674, 74, 1462, 334, 5, 47, 6, 55, 1300, 2, 2, 1841, 4, 372, 11, 27, 113, 29, 9, 24, 565, 195, 8, 2, 48, 25, 181, 8, 67, 52, 116, 5, 4, 635, 7, 113, 81, 24, 717, 14, 20, 514, 139, 4, 3756, 582, 8, 1868, 2, 5, 32, 4, 231, 7, 6, 2702, 46, 7, 1912, 2714, 15, 13, 38, 2, 75, 26, 32, 1912, 2, 514, 4414, 742, 12, 9, 64, 34, 170, 2, 15, 25, 923, 15, 25, 26, 66, 170, 4451, 742, 25, 28, 6, 2, 4421, 21, 121, 9, 129, 483, 10, 10]),\n",
       "         ...,\n",
       "         list([1, 14, 390, 7, 2, 1194, 285, 4, 123, 9, 44, 8, 130, 45, 840, 811, 5, 32, 609, 9, 2244, 1888, 11, 14, 390, 4, 2, 663, 721, 35, 1356, 773, 884, 2, 8, 4, 2, 4, 2910, 90, 39, 4, 2, 2, 54, 3034, 29, 2, 11, 17, 6, 2, 5, 95, 83, 27, 2734, 2391, 29, 2, 3913, 6, 1513, 63, 484, 2, 41, 46, 5, 2201, 1098, 41, 95, 2, 2, 3913, 51, 9, 317, 7, 4, 1513, 2, 266, 39, 4, 2, 5, 560, 4, 2, 3341, 159, 385, 516, 4, 1042, 21, 112, 4, 671, 7, 31, 12, 43, 2, 90, 4892, 266, 8, 2, 4, 85, 2481, 5, 494, 8, 169, 5, 2330, 90, 18, 147, 2, 2086, 9, 11, 4, 2, 269, 8, 169, 3636, 54, 5, 2, 140, 46, 83, 4, 890, 8, 169, 4, 2734, 4, 2734, 659, 98, 103, 68, 985, 4, 4701, 923, 15, 6, 370, 1059, 285, 54, 36, 79, 145, 8, 2, 269, 8, 985, 4, 1776, 5, 103, 36, 2, 6, 6, 1718, 825, 2, 3234, 2, 1077, 41, 2, 8, 847, 84, 46, 7, 4, 96, 38, 59, 70, 79, 8, 4, 1550, 21, 36, 79, 68, 8, 522, 5, 2, 1442, 5, 43, 54, 9, 44, 8, 79, 324, 58, 9, 2, 8, 121, 36, 721, 884, 2, 8, 4, 2, 3682, 11, 5, 2, 5, 2, 21, 2, 9, 131, 11, 4, 2, 38, 1098, 4, 1042, 5, 2, 46, 7, 4, 2, 54, 4892, 417, 266, 29, 191, 2, 9, 351, 5, 38, 9, 4, 671, 7, 289, 18, 150, 1276, 14, 390, 16, 619, 16, 4, 7, 32, 7, 98, 13, 62, 119, 8, 28, 41, 671, 7, 2, 13, 66, 92, 104, 2, 144, 7, 435, 8, 4, 2, 88, 48, 59, 161, 586, 28, 556, 21, 2, 961, 4, 671, 7, 289, 295, 174, 5, 146, 654, 19, 4, 3769, 3724]),\n",
       "         list([1, 13, 435, 83, 14, 22, 1017, 1383, 18, 6, 2928, 1278, 11, 405, 2, 7, 4039, 2228, 21, 51, 13, 188, 16, 53, 7, 6, 1162, 3905, 1010, 19, 230, 99, 76, 662, 5, 24, 195, 206, 45, 788, 15, 14, 22, 16, 93, 23, 6, 352, 4, 1979, 26, 2, 5, 862, 324, 137, 4, 116, 889, 6, 176, 8, 30, 4630, 82, 4, 114, 2679, 23, 6, 3993, 7, 2, 6, 336, 5, 107, 3197, 15, 2114, 6, 3817, 7, 1818, 103, 880, 49, 2, 36, 216, 638, 6, 2816, 2, 34, 6, 185, 250, 5, 41, 2, 5, 32, 14, 9, 579, 11, 2183, 34, 4, 185, 250, 3880, 2, 11, 35, 2, 45, 788, 15, 907, 2393, 5, 1024, 2, 197, 36, 71, 231, 142, 66, 1621, 21, 466, 94, 118, 2048, 1226, 7, 609, 2527, 9, 43, 99, 357, 8, 1465, 4, 529, 4, 22, 2, 23, 18, 44, 2, 234, 5, 91, 7, 12, 3202, 7, 357, 105, 2, 125, 357, 5, 196, 2, 414, 4, 64, 52, 155, 13, 28, 8, 135, 44, 4, 22, 9, 19, 2, 8, 4, 228, 63, 9, 52, 11, 1370, 4, 277, 9, 4, 64, 85, 52, 155, 44, 4, 20, 5, 198, 64, 88, 45, 4, 236, 155, 15, 571, 13, 586, 386, 259, 2, 2, 14, 180, 50, 16, 76, 128, 1157, 93, 11, 4, 4039]),\n",
       "         list([1, 1252, 54, 13, 435, 8, 67, 14, 20, 33, 4, 2, 750, 11, 2, 13, 122, 24, 535, 76, 13, 435, 8, 14, 20, 64, 88, 13, 2626, 1400, 45, 6, 2, 20, 4092, 30, 52, 18, 6, 462, 95, 13, 1829, 180, 5, 296, 12, 5, 219, 138, 36, 2471, 2, 2, 3561, 8, 297, 2, 2, 29, 9, 242, 31, 7, 4, 2, 493, 23, 4, 194, 268, 76, 433, 11, 61, 652, 74, 2281, 42, 1655, 5, 47, 31, 194, 3079, 8, 85, 102, 15, 2, 72, 8, 6, 189, 20, 12, 287, 2, 2, 17, 294, 37, 9, 406, 29, 47, 6, 483, 57, 551, 89, 2509, 5, 948, 12, 9, 29, 764, 1460, 142, 15, 1655, 115, 127, 42, 739, 8, 123, 29, 764, 2, 5, 1742, 151, 174, 199, 7, 98, 2140, 63, 25, 80, 1495, 48, 25, 67, 4, 20, 32, 11, 32, 6, 275, 585, 11, 61, 652, 74, 111, 2, 5, 12, 770, 72, 11, 6, 171, 771, 17, 11, 37, 1452, 11, 4, 130])], dtype=object),\n",
       "  array([1, 1, 1, ..., 1, 0, 1])))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.load_data(num_words=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...,   19  178   32]\n",
      " [   0    0    0 ...,   16  145   95]\n",
      " [   0    0    0 ...,    7  129  113]\n",
      " ..., \n",
      " [   0    0    0 ...,    4 3586    2]\n",
      " [   0    0    0 ...,   12    9   23]\n",
      " [   0    0    0 ...,  204  131    9]]\n"
     ]
    }
   ],
   "source": [
    "# Pad vectors < 500 words with zeros, else truncate\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               4000250   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "41s - loss: 0.5726 - acc: 0.6542 - val_loss: 0.3268 - val_acc: 0.8620\n",
      "Epoch 2/2\n",
      "40s - loss: 0.2270 - acc: 0.9108 - val_loss: 0.2857 - val_acc: 0.8803\n",
      "Accuracy: 88.03%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting to see at about what frequency index unambiguously domain specific terms take over. I imagine the more varied datasets integrated into the model, the more generalised terms are pushed to the top of the frequency indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1980, 1980, 1980, 3, 5132, 500, 960, 10, 827, 63164, 587, 827, 10, 1980, 960, 827, 1601, 1206, 10, 3360, 3, 2011, 2011, 5132, 2011, 960, 3, 1476, 3360, 3, 1206, 1476, 3, 1980, 960, 1989, 1601, 1476, 2292, 1601, 1328, 960, 1476, 827, 2020, 1601, 1203, 1328, 2020, 827, 960, 2020, 3, 1092, 500, 960, 960, 3360, 1092, 3, 500, 500, 2011, 10, 3360, 1328, 10, 3360, 3, 1961, 3, 1145, 1476, 10, 1654, 827, 1206, 1601, 1476, 3, 1206, 960, 1989, 1980, 1601, 3360, 827, 2020, 587, 2020, 5132, 3360, 1601, 827, 587, 960, 960, 1989, 2020, 3, 827, 3, 2011, 2011, 827, 2020, 960, 1206, 1476, 3, 1980, 960, 1989, 1601, 1476, 2292, 1206, 1203, 587, 587, 1989, 3, 587, 3, 500, 1601, 1203, 827, 1206, 827, 960, 1476, 587, 2292, 10, 1980, 1980, 10, 3360, 1328, 827, 2020, 960, 3, 1476, 827, 10, 1145, 2011, 960, 1989, 2020, 10, 1145, 2020, 10, 3360, 1145, 2011, 1203, 1092, 960, 1092, 1989, 1601, 1476, 1092, 587, 2011, 10, 2292, 960, 10, 3360, 827, 1203, 10, 827, 10, 1961, 960, 3, 3360, 1092, 1206, 2011, 960, 1742, 10, 500, 2011, 960, 3, 3360, 1092, 1961, 960, 1476, 587, 3, 827, 10, 2011, 960, 1601, 1328, 960, 1476, 1989, 3, 587, 587, 1601, 2011, 1092]]\n"
     ]
    }
   ],
   "source": [
    "# Test string to measure sentiment #\n",
    "test_str = 'Hmm, maybe it’s time to finally learn a framework, Roger thought. He had been dabbling in JavaScript for a few months. Why not see what all the framework fuss was about? After skimming the article — which included words like “intuitive” and “flexible” and “versatile” — Roger was sold.'\n",
    "\n",
    "# We need to get the word index data to convert the freq indexes back to the assosciated word #\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# convert to frequency representation by word index #\n",
    "test_encoded = [[word_index[w] for w in test_str if w in word_index]]\n",
    "\n",
    "print(test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0  1980  1980  1980\n",
      "      3  5132   500   960    10   827 63164   587   827    10  1980   960\n",
      "    827  1601  1206    10  3360     3  2011  2011  5132  2011   960     3\n",
      "   1476  3360     3  1206  1476     3  1980   960  1989  1601  1476  2292\n",
      "   1601  1328   960  1476   827  2020  1601  1203  1328  2020   827   960\n",
      "   2020     3  1092   500   960   960  3360  1092     3   500   500  2011\n",
      "     10  3360  1328    10  3360     3  1961     3  1145  1476    10  1654\n",
      "    827  1206  1601  1476     3  1206   960  1989  1980  1601  3360   827\n",
      "   2020   587  2020  5132  3360  1601   827   587   960   960  1989  2020\n",
      "      3   827     3  2011  2011   827  2020   960  1206  1476     3  1980\n",
      "    960  1989  1601  1476  2292  1206  1203   587   587  1989     3   587\n",
      "      3   500  1601  1203   827  1206   827   960  1476   587  2292    10\n",
      "   1980  1980    10  3360  1328   827  2020   960     3  1476   827    10\n",
      "   1145  2011   960  1989  2020    10  1145  2020    10  3360  1145  2011\n",
      "   1203  1092   960  1092  1989  1601  1476  1092   587  2011    10  2292\n",
      "    960    10  3360   827  1203    10   827    10  1961   960     3  3360\n",
      "   1092  1206  2011   960  1742    10   500  2011   960     3  3360  1092\n",
      "   1961   960  1476   587     3   827    10  2011   960  1601  1328   960\n",
      "   1476  1989     3   587   587  1601  2011  1092]]\n"
     ]
    }
   ],
   "source": [
    "# Pad the sequence to make it an equal length array #\n",
    "test_padded = sequence.pad_sequences(test_encoded, maxlen=max_words)\n",
    "\n",
    "print(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0  1980  1980  1980\n",
      "      3  5132   500   960    10   827 63164   587   827    10  1980   960\n",
      "    827  1601  1206    10  3360     3  2011  2011  5132  2011   960     3\n",
      "   1476  3360     3  1206  1476     3  1980   960  1989  1601  1476  2292\n",
      "   1601  1328   960  1476   827  2020  1601  1203  1328  2020   827   960\n",
      "   2020     3  1092   500   960   960  3360  1092     3   500   500  2011\n",
      "     10  3360  1328    10  3360     3  1961     3  1145  1476    10  1654\n",
      "    827  1206  1601  1476     3  1206   960  1989  1980  1601  3360   827\n",
      "   2020   587  2020  5132  3360  1601   827   587   960   960  1989  2020\n",
      "      3   827     3  2011  2011   827  2020   960  1206  1476     3  1980\n",
      "    960  1989  1601  1476  2292  1206  1203   587   587  1989     3   587\n",
      "      3   500  1601  1203   827  1206   827   960  1476   587  2292    10\n",
      "   1980  1980    10  3360  1328   827  2020   960     3  1476   827    10\n",
      "   1145  2011   960  1989  2020    10  1145  2020    10  3360  1145  2011\n",
      "   1203  1092   960  1092  1989  1601  1476  1092   587  2011    10  2292\n",
      "    960    10  3360   827  1203    10   827    10  1961   960     3  3360\n",
      "   1092  1206  2011   960  1742    10   500  2011   960     3  3360  1092\n",
      "   1961   960  1476   587     3   827    10  2011   960  1601  1328   960\n",
      "   1476  1989     3   587   587  1601  2011  1092]]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the array #\n",
    "vector = np.array([test_padded.flatten()])\n",
    "print(vector)\n",
    "\n",
    "# replace word encodings out of range with 0 #\n",
    "vector[vector > 5000] = 0\n",
    "\n",
    "#it was already flat #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x7f0c1335e080>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97481537]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the sentiment value of the vector-representation of our phrase #\n",
    "model.predict(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0 1145 1601 1203\n",
      "  2011 1092 3360 1601  827 2292  960  960 1654 1654    3 1145  960 1989\n",
      "    10  827 2020    3 2011 2011  827 2020  960  587  960 2011   10  827\n",
      "   960 1476    3 1476 5132 1206 1601 2011 2292    3  587  827 2020  960\n",
      "  5132 1328 2011    3 3360 1145  960 1092 1206 1476 1601 1980  587 1203\n",
      "   500 1465  960 1145  827  827 1601  587 1203  500 1465  960 1145  827\n",
      "     3 3360 1092  960 3360  827  960 1476  960 1092   10 3360  827 1601\n",
      "  1092  960  960 1654 1092   10  587 1654 1203  827  960 1601 1476 1980\n",
      "     3 1092  960 1145 1601 3360 1961  960 1476  587    3  827   10 1601\n",
      "  3360  587 1654    3 1476 2292 2011  960 1989   10  827 2020  960 1654\n",
      "    10 1328 1476    3 1980  587    3 3360 1092 2020    3 1654 1654 5132\n",
      "  1989   10  827  827   10 1145   10  587 1980  587]]\n"
     ]
    }
   ],
   "source": [
    "# Test string to measure sentiment #\n",
    "test_str = 'I could not keep pace with all these literary folk as they glanced from subject to subject and entered into deep dispute, or made conversation sparkle with epigrams and happy witticisms.'\n",
    "\n",
    "# We need to get the word index data to convert the freq indexes back to the assosciated word #\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# convert to frequency representation by word index #\n",
    "test_encoded = [[word_index[w] for w in test_str if w in word_index]]\n",
    "\n",
    "# Pad the sequence to make it an equal length array #\n",
    "test_padded = sequence.pad_sequences(test_encoded, maxlen=max_words)\n",
    "\n",
    "# Flatten the array #\n",
    "vector = np.array([test_padded.flatten()])\n",
    "print(vector)\n",
    "\n",
    "# replace word encodings out of range with 0 #\n",
    "vector[vector > 5000] = 0\n",
    "\n",
    "#it was already flat #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97321588]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the sentiment value of the vector-representation of our phrase #\n",
    "model.predict(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0  500    3 1092    3 3360 1328\n",
      "  1476 5132 1980  960    3 3360 1476 1203 1092  960]]\n"
     ]
    }
   ],
   "source": [
    "# Test string to measure sentiment #\n",
    "test_str = 'bad angry mean rude'\n",
    "# We need to get the word index data to convert the freq indexes back to the assosciated word #\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# convert to frequency representation by word index #\n",
    "test_encoded = [[word_index[w] for w in test_str if w in word_index]]\n",
    "\n",
    "# Pad the sequence to make it an equal length array #\n",
    "test_padded = sequence.pad_sequences(test_encoded, maxlen=max_words)\n",
    "\n",
    "# Flatten the array #\n",
    "vector = np.array([test_padded.flatten()])\n",
    "print(vector)\n",
    "\n",
    "# replace word encodings out of range with 0 #\n",
    "vector[vector > 5000] = 0\n",
    "\n",
    "#it was already flat #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62631774]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the sentiment value of the vector-representation of our phrase #\n",
    "model.predict(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the sentiment for custom excerpts seems to be really ambiguous. We should try rolling it on an actual dataset and comparing it to the output of google's sentiment engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
